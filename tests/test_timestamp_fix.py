#!/usr/bin/env python3
"""
Test script for timestamp accuracy in PreenCut
"""

import sys
import os
import json

# Add the project root to the Python path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from modules.llm_processor import LLMProcessor

def test_timestamp_accuracy():
    """Test the new timestamp-aware processing"""
    print("Testing PreenCut timestamp accuracy improvements...")
    
    # Create sample subtitle segments with realistic timestamps
    sample_segments = [
        {"start": 0.0, "end": 3.5, "text": "Xin ch√†o c√°c b·∫°n, h√¥m nay ch√∫ng ta s·∫Ω h·ªçc v·ªÅ kinh t·∫ø."},
        {"start": 3.5, "end": 7.2, "text": "ƒê·∫ßu ti√™n, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu v·ªÅ th·ªã tr∆∞·ªùng ch·ª©ng kho√°n."},
        {"start": 7.2, "end": 12.8, "text": "Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n l√† n∆°i mua b√°n c·ªï phi·∫øu c·ªßa c√°c c√¥ng ty."},
        {"start": 12.8, "end": 18.1, "text": "Gi√° c·ªï phi·∫øu thay ƒë·ªïi theo cung v√† c·∫ßu tr√™n th·ªã tr∆∞·ªùng."},
        {"start": 18.1, "end": 24.3, "text": "B√¢y gi·ªù ch√∫ng ta s·∫Ω chuy·ªÉn sang ch·ªß ƒë·ªÅ kh√°c l√† v·ªÅ c√¥ng ngh·ªá."},
        {"start": 24.3, "end": 29.7, "text": "C√¥ng ngh·ªá AI ƒëang ph√°t tri·ªÉn r·∫•t nhanh trong nh·ªØng nƒÉm g·∫ßn ƒë√¢y."},
        {"start": 29.7, "end": 35.2, "text": "Machine learning l√† m·ªôt ph·∫ßn quan tr·ªçng c·ªßa AI."},
        {"start": 35.2, "end": 40.8, "text": "H√¥m nay ch√∫ng ta ƒë√£ h·ªçc ƒë∆∞·ª£c nhi·ªÅu ƒëi·ªÅu th√∫ v·ªã."}
    ]
    
    # Test the new logical segmentation
    try:
        llm = LLMProcessor("llama3.1")  # Use default model
        
        print("\n1. Testing logical segmentation...")
        logical_segments = llm._create_logical_segments(sample_segments, target_duration=20)
        
        print(f"   Original segments: {len(sample_segments)}")
        print(f"   Logical segments: {len(logical_segments)}")
        
        for i, seg in enumerate(logical_segments):
            duration = seg['end'] - seg['start']
            print(f"   Segment {i+1}: {seg['start']:.1f}s - {seg['end']:.1f}s ({duration:.1f}s)")
            print(f"   Content: {seg['text'][:50]}...")
        
        print("\n2. Testing narrative segmentation...")
        # Create a mock align_result
        align_result = {
            'segments': sample_segments
        }
        
        # Test topic extraction
        prompt = "th·ªã tr∆∞·ªùng ch·ª©ng kho√°n"
        narrative_segments = llm.segment_narrative(align_result, prompt)
        
        print(f"   Found {len(narrative_segments)} segments for topic: '{prompt}'")
        for i, seg in enumerate(narrative_segments):
            duration = seg['end'] - seg['start']
            print(f"   Match {i+1}: {seg['start']:.1f}s - {seg['end']:.1f}s ({duration:.1f}s)")
            print(f"   Summary: {seg['summary']}")
            print(f"   Relevance: {seg.get('relevance', 'N/A')}")
        
        print(f"\n‚úÖ Timestamp accuracy test completed successfully!")
        print(f"   Key improvements:")
        print(f"   - Uses actual subtitle timestamps instead of generated ones")
        print(f"   - Groups into logical segments of appropriate duration")
        print(f"   - Sentence-level analysis for topic extraction")
        print(f"   - Merges and extends segments for better context")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_timestamp_accuracy()
    if success:
        print("\nüéâ All timestamp accuracy tests passed!")
        print("The fixes should resolve the timing issues you experienced.")
    else:
        print("\n‚ùå Some tests failed. Please check the errors above.")
    
    sys.exit(0 if success else 1)
